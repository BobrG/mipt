{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL фреймворки\n",
    "\n",
    "Почти полный список RL фреймворков можно посмотреть в [Open-source RL](https://docs.google.com/spreadsheets/d/1EeFPd-XIQ3mq_9snTlAZSsFY7Hbnmd7P5bbT8LPuMn0/edit#gid=0). Не хватает [PARL](https://github.com/PaddlePaddle/PARL) и [ChainerRL](https://github.com/chainer/chainerrl).\n",
    "\n",
    "<img src=\"frameworks.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OpenAI baselines](https://github.com/openai/baselines)\n",
    "OpenAI Baselines is a set of high-quality implementations of reinforcement learning algorithms.\n",
    "\n",
    "These algorithms will make it easier for the research community to replicate, refine, and identify new ideas, and will create good baselines to build research on top of. Our DQN implementation and its variants are roughly on par with the scores in published papers. We expect they will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones.\n",
    "\n",
    "Usage example:\n",
    "```python\n",
    "python -m baselines.run --alg=deepq --env=PongNoFrameskip-v4 --num_timesteps=1e6\n",
    "```\n",
    "\n",
    "<img src=\"ailogo.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Stable baselines](https://github.com/hill-a/stable-baselines)\n",
    "Stable Baselines is a set of improved implementations of reinforcement learning algorithms based on OpenAI Baselines.\n",
    "\n",
    "You can read a detailed presentation of Stable Baselines in the [Medium article](https://towardsdatascience.com/stable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82).\n",
    "\n",
    "These algorithms will make it easier for the research community and industry to replicate, refine, and identify new ideas, and will create good baselines to build projects on top of. We expect these tools will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones. We also hope that the simplicity of these tools will allow beginners to experiment with a more advanced toolset, without being buried in implementation details.\n",
    "\n",
    "<img src=\"stableLogo.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Catalyst](https://github.com/catalyst-team/catalyst)\n",
    "<img src=\"catalyst_logo.png\">\n",
    "\n",
    "High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code/ideas reusing. Being able to research/develop something new, rather than write another regular train loop.\n",
    "\n",
    "Break the cycle - use the Catalyst! https://arxiv.org/pdf/1903.00027.pdf\n",
    "\n",
    "<img src=\"catalyst.png\">\n",
    "\n",
    "https://docs.wandb.com/library/integrations/catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from catalyst.dl import SupervisedRunner\n",
    "\n",
    "# experiment setup\n",
    "logdir = \"./logdir\"\n",
    "num_epochs = 42\n",
    "\n",
    "# data\n",
    "loaders = {\"train\": ..., \"valid\": ...}\n",
    "\n",
    "# model, criterion, optimizer\n",
    "model = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# model runner\n",
    "runner = SupervisedRunner()\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PARL](https://github.com/PaddlePaddle/PARL)\n",
    "\n",
    "<img src=\"PARL-logo.png\">\n",
    "\n",
    "PARL is a flexible and high-efficient reinforcement learning framework.\n",
    "\n",
    "Reproducible. We provide algorithms that stably reproduce the result of many influential reinforcement learning algorithms.\n",
    "\n",
    "Large Scale. Ability to support high-performance parallelization of training with thousands of CPUs and multi-GPUs.\n",
    "\n",
    "Reusable. Algorithms provided in the repository could be directly adapted to a new task by defining a forward network and training mechanism will be built automatically.\n",
    "\n",
    "Extensible. Build new algorithms quickly by inheriting the abstract class in the framework.\n",
    "\n",
    "<img src=\"parl-decorator.png\">\n",
    "\n",
    "Alogithms:\n",
    "\n",
    "- DQN\n",
    "- DDDQN\n",
    "- DDPG\n",
    "- PPO\n",
    "- IMPALA\n",
    "- A2C\n",
    "- A3C\n",
    "- TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARL vs Catalyst in NIPS Learn to Move competition\n",
    "\n",
    "[Learn to move Leaderboard](https://www.aicrowd.com/challenges/neurips-2019-learn-to-move-walk-around/leaderboards)\n",
    "\n",
    "<img src=\"tomove.png\">\n",
    "\n",
    "[First place: PARL Baidu](https://www.youtube.com/watch?v=FD2lGv-4BLE&feature=youtu.be) Bo Zhou, Hongsheng Zeng, Fan Wang, Yunxiang Li, and Hao Tian\n",
    "\n",
    "[Second place: Catalyst](https://www.youtube.com/watch?v=WuqNdNBVzzI&feature=youtu.be) Sergey Kolesnikov and Valentin Khrulkov\n",
    "\n",
    "[Third place: SimBodyWithDummyPlug](https://www.youtube.com/watch?v=DfPPiTsuB4E&feature=youtu.be) Dmitry Akimov\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ChainerRL](https://github.com/chainer/chainerrl)\n",
    "\n",
    "<img src=\"ChainerRL.png\">\n",
    "\n",
    "ChainerRL is a deep reinforcement learning library that implements various state-of-the-art deep reinforcement algorithms in Python using [Chainer](https://github.com/chainer/chainer), a flexible deep learning framework.\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "| Algorithm | Discrete Action | Continous Action | Recurrent Model | Batch Training | CPU Async Training |\n",
    "|:----------|:---------------:|:----------------:|:---------------:|:--------------:|:------------------:|\n",
    "| DQN (including DoubleDQN etc.) | ✓ | ✓ (NAF) | ✓ | ✓ | x |\n",
    "| Categorical DQN | ✓ | x | ✓ | ✓ | x |\n",
    "| Rainbow | ✓ | x | ✓ | ✓ | x |\n",
    "| IQN | ✓ | x | ✓ | ✓ | x |\n",
    "| DDPG | x | ✓ | ✓ | ✓ | x |\n",
    "| A3C  | ✓ | ✓ | ✓ | ✓ (A2C) | ✓ |\n",
    "| ACER | ✓ | ✓ | ✓ | x | ✓ |\n",
    "| NSQ (N-step Q-learning) | ✓ | ✓ (NAF) | ✓ | x | ✓ |\n",
    "| PCL (Path Consistency Learning) | ✓ | ✓ | ✓ | x | ✓ |\n",
    "| PPO  | ✓ | ✓ | ✓ | ✓ | x |\n",
    "| TRPO | ✓ | ✓ | ✓ | ✓ | x |\n",
    "| TD3 | x | ✓ | x | ✓ | x |\n",
    "| SAC | x | ✓ | x | ✓ | x |\n",
    "\n",
    "Following algorithms have been implemented in ChainerRL:\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание: Выбрать несколько фреймворков и воспроизвести стандартные эксперименты. Разобраться в том, как модифицировать код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
