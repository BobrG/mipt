{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Actor-Critic\n", "\n", "\n", "<img src=\"ac_scheme.png\">\n", "\n", "«Критик» оценивает функцию полезности. Это может быть полезность действия ($Q$) или полезность состояния ($V$).\n", "\n", "«Актор» обновляет распределение стратегии в направлении, предложенном Критиком.\n", "\n", "\n", "Псевдокод для $Q$ версии алгоритма приведен ниже:\n", "<img src=\"alg_ac.png\" style=\"width: 700px\">\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Задание 1. Заполните пропуски для $V$ версии алгоритма Actor-Critic"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import gym\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torch.distributions import Categorical\n", "\n", "learning_rate = 0.0001\n", "gamma = 0.98"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["class ActorCritic(nn.Module):\n", "    def __init__(self):\n", "        super(ActorCritic, self).__init__()\n", "        self.data = []\n", "\n", "        # создаем сеть с двумя головами для pi и V (подсказка - смотрим на методы pi и v)\n", "        ########## Solution ############\n", "        self.fc1 = nn.Linear(4, 256)\n", "        self.fc_pi = nn.Linear(256, 2)\n", "        self.fc_v = nn.Linear(256, 1)\n", "        ################################\n", "\n", "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n", "\n", "    def pi(self, x, softmax_dim=0):\n", "        x = F.relu(self.fc1(x))\n", "        x = self.fc_pi(x)\n", "        prob = F.softmax(x, dim=softmax_dim)\n", "        return prob\n", "\n", "    def v(self, x):\n", "        x = F.relu(self.fc1(x))\n", "        v = self.fc_v(x)\n", "        return v\n", "\n", "    def put_data(self, transition):\n", "        self.data.append(transition)\n", "\n", "    def make_batch(self):\n", "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n", "\n", "        for transition in self.data:\n", "            # собираем батч из сохранненых кортежей\n", "            # не забывайте сделать клиппинг вознаграждений!\n", "            ########## Solution ############\n", "            s, a, r, s_prime, done = transition\n", "            s_lst.append(s)\n", "            a_lst.append([a])\n", "            r_lst.append([r / 100])\n", "            s_prime_lst.append(s_prime)\n", "            ################################\n", "            # не забываем про окончание эпизода\n", "            done_mask = 0.0 if done else 1.0\n", "            done_lst.append([done_mask])\n", "\n", "        s_batch, a_batch, r_batch, s_prime_batch, done_batch = torch.tensor(s_lst, dtype=torch.float), torch.tensor(\n", "            a_lst), \\\n", "                                                               torch.tensor(r_lst, dtype=torch.float), torch.tensor(\n", "            s_prime_lst, dtype=torch.float), \\\n", "                                                               torch.tensor(done_lst, dtype=torch.float)\n", "        self.data = []\n", "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\n", "\n", "    def train_net(self):\n", "        # получаем батч\n", "        # s, a, r, s_prime, done =\n", "        ########## Solution ############\n", "        s, a, r, s_prime, done = self.make_batch()\n", "        ################################\n", "\n", "        # считаем td target(r + gamma ...) и td ошибку (td_target - v)\n", "        # td_target = \n", "        # delta = \n", "        ########## Solution ############\n", "        td_target = r + gamma * self.v(s_prime) * done\n", "        delta = td_target - self.v(s)\n", "        ################################\n", "\n", "        # получаем распределение\n", "        pi = self.pi(s, softmax_dim=1)\n", "        pi_a = pi.gather(1, a)\n", "\n", "        # считаем td_loss (подсказка можно воспользоваться smooth_l1_loss) (не забыаем про лишние градиенты!)\n", "        # td_loss = \n", "        td_loss = F.smooth_l1_loss(self.v(s), td_target.detach())\n", "        # считаем loss актора (-pi_a) * delta (не забыаем про лишние градиенты!)\n", "        # a_loss =  \n", "        a_loss = -torch.log(pi_a) * delta.detach()\n", "\n", "        # вызываем backward и делаем шаг оптимизатора для каждого лосса\n", "        ########## Solution ############\n", "        self.optimizer.zero_grad()\n", "        loss = a_loss + td_loss\n", "        loss.mean().backward()\n", "        self.optimizer.step()\n", "        ################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Задание 2. Подбираем гиперпараметры и строим графики. Как влияет клиппинг вознаграждений на итоговую сходимость?"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["# of episode :20, avg score : 22.2\n", "# of episode :40, avg score : 21.7\n", "# of episode :60, avg score : 22.4\n", "# of episode :80, avg score : 27.1\n", "# of episode :100, avg score : 36.6\n", "# of episode :120, avg score : 44.2\n", "# of episode :140, avg score : 47.5\n", "# of episode :160, avg score : 52.1\n", "# of episode :180, avg score : 60.0\n", "# of episode :200, avg score : 90.0\n", "# of episode :220, avg score : 114.8\n", "# of episode :240, avg score : 105.7\n", "# of episode :260, avg score : 124.5\n", "# of episode :280, avg score : 207.2\n", "# of episode :300, avg score : 217.2\n", "# of episode :320, avg score : 188.5\n", "# of episode :340, avg score : 248.6\n", "# of episode :360, avg score : 238.3\n", "# of episode :380, avg score : 217.2\n", "# of episode :400, avg score : 145.6\n", "# of episode :420, avg score : 124.8\n", "# of episode :440, avg score : 143.0\n", "# of episode :460, avg score : 196.6\n", "# of episode :480, avg score : 233.0\n", "# of episode :500, avg score : 212.7\n", "# of episode :520, avg score : 253.3\n", "# of episode :540, avg score : 225.3\n", "# of episode :560, avg score : 232.4\n", "# of episode :580, avg score : 172.1\n", "# of episode :600, avg score : 262.7\n", "# of episode :620, avg score : 287.6\n", "# of episode :640, avg score : 251.4\n", "# of episode :660, avg score : 256.2\n", "# of episode :680, avg score : 316.1\n", "# of episode :700, avg score : 362.9\n", "# of episode :720, avg score : 409.7\n", "# of episode :740, avg score : 414.8\n", "# of episode :760, avg score : 440.1\n", "# of episode :780, avg score : 471.2\n", "# of episode :800, avg score : 353.8\n", "# of episode :820, avg score : 324.2\n", "# of episode :840, avg score : 283.1\n", "# of episode :860, avg score : 392.8\n", "# of episode :880, avg score : 402.9\n", "# of episode :900, avg score : 317.6\n", "# of episode :920, avg score : 357.9\n", "# of episode :940, avg score : 297.0\n", "# of episode :960, avg score : 396.1\n", "# of episode :980, avg score : 355.9\n", "# of episode :1000, avg score : 444.8\n"]}], "source": ["def run():\n", "    env = gym.make('CartPole-v1')\n", "    model = ActorCritic()\n", "    n_rollout = 5\n", "    print_interval = 20\n", "    score = 0.0\n", "\n", "    for n_epi in range(1001):\n", "        done = False\n", "        s = env.reset()\n", "        while not done:\n", "            for t in range(n_rollout):\n", "                prob = model.pi(torch.from_numpy(s).float())\n", "                m = Categorical(prob)\n", "                a = m.sample().item()\n", "                s_prime, r, done, info = env.step(a)\n", "                model.put_data((s, a, r, s_prime, done))\n", "\n", "                s = s_prime\n", "                score += r\n", "\n", "                if done:\n", "                    break\n", "\n", "            model.train_net()\n", "\n", "        if n_epi % print_interval == 0 and n_epi != 0:\n", "            print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score / print_interval))\n", "            score = 0.0\n", "    env.close()\n", "\n", "\n", "run()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.5rc1"}}, "nbformat": 4, "nbformat_minor": 2}